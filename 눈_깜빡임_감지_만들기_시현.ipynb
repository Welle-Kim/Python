{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "눈 깜빡임 감지 만들기 시현.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDcfW272ZEzxUKQ2aemBpF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Welle-Kim/Python/blob/master/%EB%88%88_%EA%B9%9C%EB%B9%A1%EC%9E%84_%EA%B0%90%EC%A7%80_%EB%A7%8C%EB%93%A4%EA%B8%B0_%EC%8B%9C%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUudVJT_qLLP",
        "outputId": "31525ec9-e54f-4412-a4e3-03107a4efef5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dx98Mlj4nXrb"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input,Activation,Conv2D,Flatten,Dense,MaxPooling2D\n",
        "from keras.models import Model,load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "plt.style.use(\"dark_background\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.load(\"x_train.npy\").astype(np.float32)\n",
        "y_train=np.load(\"y_train.npy\").astype(np.float32)\n",
        "x_val=np.load(\"x_val.npy\").astype(np.float32)\n",
        "y_val=np.load(\"y_val.npy\").astype(np.float32)\n",
        "\n",
        "print(x_train.shape,y_train.shape)\n",
        "print(x_val.shape,y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6t0tI1vp-Yu",
        "outputId": "0f8b267c-1084-46c6-8c7f-448c09fee49f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2586, 26, 34, 1) (2586, 1)\n",
            "(288, 26, 34, 1) (288, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0이면 눈이 감김\n",
        "###1이면 눈이 감김"
      ],
      "metadata": {
        "id": "keXr3h_LrHC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(\n",
        "  rescale=1./255,\n",
        "  rotation_range=10,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  shear_range=0.2\n",
        ")\n",
        "\n",
        "val_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator=train_datagen.flow(\n",
        "    x=x_train,y=y_train,\n",
        "    batch_size=32,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator=val_datagen.flow(\n",
        "    x=x_val,y=y_val,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "-s74BQ_4q3ZJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=Input(shape=(26,34,1))\n",
        "\n",
        "net=Conv2D(32,kernel_size=3,strides=1,padding=\"same\",activation=\"relu\")(inputs)\n",
        "net=MaxPooling2D(pool_size=2)(net)\n",
        "\n",
        "net=Conv2D(64,kernel_size=3,strides=1,padding=\"same\",activation=\"relu\")(net)\n",
        "net=MaxPooling2D(pool_size=2)(net)\n",
        "\n",
        "net=Conv2D(128,kernel_size=3,strides=1,padding=\"same\",activation=\"relu\")(net)\n",
        "net=MaxPooling2D(pool_size=2)(net)\n",
        "\n",
        "net=Flatten()(net)\n",
        "\n",
        "\n",
        "net=Dense(512)(net)\n",
        "net=Activation('relu')(net)\n",
        "net=Dense(1)(net)\n",
        "outputs=Activation(\"sigmoid\")(net)\n",
        "\n",
        "model=Model(inputs=inputs,outputs=outputs)\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"acc\"])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxsQXFmUr9Gg",
        "outputId": "648a87dd-c0d7-407a-ec67-1419c43ae547"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 26, 34, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 13, 17, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 13, 17, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 6, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 6, 8, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 3, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1536)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               786944    \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 880,129\n",
            "Trainable params: 880,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time=datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,epochs=50, validation_data= val_generator,\n",
        "    callbacks=[\n",
        "    ModelCheckpoint(\"models%s.h5\"%(start_time),monitor=\"val_acc\",save_best_only=True,mode=\"max\",verbose=1)\n",
        "    ,ReduceLROnPlateau(monitor=\"val_acc\",factor=0.2,patience=10,verbose=1,mode=\"auto\",min_delta=0.0001, cooldown=0, min_lr=1e-05)\n",
        "  ]\n",
        ")\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVkQLMjJtddS",
        "outputId": "b8c766c3-2ae5-4022-f0af-2501a2cf2d8f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.4105 - acc: 0.8140\n",
            "Epoch 1: val_acc improved from -inf to 0.82292, saving model to models2022_06_07_01_48_07.h5\n",
            "81/81 [==============================] - 10s 106ms/step - loss: 0.4105 - acc: 0.8140 - val_loss: 0.3769 - val_acc: 0.8229 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.2589 - acc: 0.8956\n",
            "Epoch 2: val_acc improved from 0.82292 to 0.93403, saving model to models2022_06_07_01_48_07.h5\n",
            "81/81 [==============================] - 10s 122ms/step - loss: 0.2589 - acc: 0.8956 - val_loss: 0.2423 - val_acc: 0.9340 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.2012 - acc: 0.9238\n",
            "Epoch 3: val_acc improved from 0.93403 to 0.96528, saving model to models2022_06_07_01_48_07.h5\n",
            "81/81 [==============================] - 8s 100ms/step - loss: 0.2012 - acc: 0.9238 - val_loss: 0.0900 - val_acc: 0.9653 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.1477 - acc: 0.9490\n",
            "Epoch 4: val_acc improved from 0.96528 to 0.98264, saving model to models2022_06_07_01_48_07.h5\n",
            "81/81 [==============================] - 8s 100ms/step - loss: 0.1477 - acc: 0.9490 - val_loss: 0.0557 - val_acc: 0.9826 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.1167 - acc: 0.9590\n",
            "Epoch 5: val_acc did not improve from 0.98264\n",
            "81/81 [==============================] - 8s 99ms/step - loss: 0.1167 - acc: 0.9590 - val_loss: 0.0688 - val_acc: 0.9722 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0978 - acc: 0.9660\n",
            "Epoch 6: val_acc did not improve from 0.98264\n",
            "81/81 [==============================] - 8s 100ms/step - loss: 0.0978 - acc: 0.9660 - val_loss: 0.0518 - val_acc: 0.9826 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0956 - acc: 0.9683\n",
            "Epoch 7: val_acc did not improve from 0.98264\n",
            "81/81 [==============================] - 8s 101ms/step - loss: 0.0956 - acc: 0.9683 - val_loss: 0.0945 - val_acc: 0.9688 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0747 - acc: 0.9787\n",
            "Epoch 8: val_acc improved from 0.98264 to 0.98611, saving model to models2022_06_07_01_48_07.h5\n",
            "81/81 [==============================] - 8s 99ms/step - loss: 0.0747 - acc: 0.9787 - val_loss: 0.0589 - val_acc: 0.9861 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0867 - acc: 0.9749\n",
            "Epoch 9: val_acc improved from 0.98611 to 0.99653, saving model to models2022_06_07_01_48_07.h5\n",
            "81/81 [==============================] - 8s 103ms/step - loss: 0.0867 - acc: 0.9749 - val_loss: 0.0222 - val_acc: 0.9965 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0573 - acc: 0.9791\n",
            "Epoch 10: val_acc did not improve from 0.99653\n",
            "81/81 [==============================] - 8s 103ms/step - loss: 0.0573 - acc: 0.9791 - val_loss: 0.0351 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0574 - acc: 0.9818\n",
            "Epoch 11: val_acc did not improve from 0.99653\n",
            "81/81 [==============================] - 12s 144ms/step - loss: 0.0574 - acc: 0.9818 - val_loss: 0.0233 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0637 - acc: 0.9783\n",
            "Epoch 12: val_acc did not improve from 0.99653\n",
            "81/81 [==============================] - 15s 190ms/step - loss: 0.0637 - acc: 0.9783 - val_loss: 0.0242 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0447 - acc: 0.9857\n",
            "Epoch 13: val_acc improved from 0.99653 to 1.00000, saving model to models2022_06_07_01_48_07.h5\n",
            "81/81 [==============================] - 15s 181ms/step - loss: 0.0447 - acc: 0.9857 - val_loss: 0.0111 - val_acc: 1.0000 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.9865\n",
            "Epoch 14: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 13s 155ms/step - loss: 0.0501 - acc: 0.9865 - val_loss: 0.0113 - val_acc: 1.0000 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0355 - acc: 0.9880\n",
            "Epoch 15: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 101ms/step - loss: 0.0355 - acc: 0.9880 - val_loss: 0.0199 - val_acc: 0.9896 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.9865\n",
            "Epoch 16: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 12s 144ms/step - loss: 0.0386 - acc: 0.9865 - val_loss: 0.0667 - val_acc: 0.9792 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0296 - acc: 0.9915\n",
            "Epoch 17: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 12s 152ms/step - loss: 0.0296 - acc: 0.9915 - val_loss: 0.0214 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0484 - acc: 0.9841\n",
            "Epoch 18: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 11s 139ms/step - loss: 0.0484 - acc: 0.9841 - val_loss: 0.0284 - val_acc: 0.9896 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0290 - acc: 0.9927\n",
            "Epoch 19: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 10s 128ms/step - loss: 0.0290 - acc: 0.9927 - val_loss: 0.0201 - val_acc: 0.9896 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0269 - acc: 0.9884\n",
            "Epoch 20: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 12s 153ms/step - loss: 0.0269 - acc: 0.9884 - val_loss: 0.0077 - val_acc: 1.0000 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0301 - acc: 0.9903\n",
            "Epoch 21: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 11s 137ms/step - loss: 0.0301 - acc: 0.9903 - val_loss: 0.0241 - val_acc: 0.9931 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0252 - acc: 0.9934\n",
            "Epoch 22: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 13s 159ms/step - loss: 0.0252 - acc: 0.9934 - val_loss: 0.0101 - val_acc: 0.9965 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0311 - acc: 0.9896\n",
            "Epoch 23: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "81/81 [==============================] - 15s 178ms/step - loss: 0.0311 - acc: 0.9896 - val_loss: 0.0495 - val_acc: 0.9826 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.9923\n",
            "Epoch 24: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 12s 145ms/step - loss: 0.0259 - acc: 0.9923 - val_loss: 0.0091 - val_acc: 0.9965 - lr: 2.0000e-04\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0172 - acc: 0.9942\n",
            "Epoch 25: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 90ms/step - loss: 0.0172 - acc: 0.9942 - val_loss: 0.0068 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9973\n",
            "Epoch 26: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 93ms/step - loss: 0.0117 - acc: 0.9973 - val_loss: 0.0057 - val_acc: 0.9965 - lr: 2.0000e-04\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0110 - acc: 0.9965\n",
            "Epoch 27: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 91ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0043 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0112 - acc: 0.9957\n",
            "Epoch 28: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 100ms/step - loss: 0.0112 - acc: 0.9957 - val_loss: 0.0058 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n",
            "Epoch 29: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 102ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0081 - acc: 0.9981\n",
            "Epoch 30: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 100ms/step - loss: 0.0081 - acc: 0.9981 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0102 - acc: 0.9973\n",
            "Epoch 31: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 10s 120ms/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9957\n",
            "Epoch 32: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 9s 106ms/step - loss: 0.0117 - acc: 0.9957 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0106 - acc: 0.9950\n",
            "Epoch 33: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "81/81 [==============================] - 11s 136ms/step - loss: 0.0106 - acc: 0.9950 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.0000e-04\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0064 - acc: 0.9977\n",
            "Epoch 34: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 101ms/step - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0071 - acc: 0.9981\n",
            "Epoch 35: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 98ms/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.0025 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0098 - acc: 0.9969\n",
            "Epoch 36: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 86ms/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0032 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0049 - acc: 0.9992\n",
            "Epoch 37: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 101ms/step - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0047 - acc: 0.9988\n",
            "Epoch 38: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 87ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0031 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9985\n",
            "Epoch 39: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 90ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0025 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0074 - acc: 0.9981\n",
            "Epoch 40: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 82ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0083 - acc: 0.9977\n",
            "Epoch 41: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 87ms/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0065 - acc: 0.9988\n",
            "Epoch 42: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 8s 94ms/step - loss: 0.0065 - acc: 0.9988 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0038 - acc: 0.9996\n",
            "Epoch 43: val_acc did not improve from 1.00000\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "81/81 [==============================] - 7s 91ms/step - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 4.0000e-05\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9988\n",
            "Epoch 44: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 87ms/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0053 - acc: 0.9981\n",
            "Epoch 45: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 88ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9992\n",
            "Epoch 46: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 84ms/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9977\n",
            "Epoch 47: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 83ms/step - loss: 0.0051 - acc: 0.9977 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0087 - acc: 0.9969\n",
            "Epoch 48: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 85ms/step - loss: 0.0087 - acc: 0.9969 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0059 - acc: 0.9981\n",
            "Epoch 49: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 83ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.0025 - val_acc: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - ETA: 0s - loss: 0.0068 - acc: 0.9981\n",
            "Epoch 50: val_acc did not improve from 1.00000\n",
            "81/81 [==============================] - 7s 84ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b1e6eb5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UPCkrpU4kCu",
        "outputId": "231e5a0f-3183-4ade-d8e7-38ca013cc0f3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2->seaborn) (4.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "model=load_model(\"models%s.h5\"%(start_time))\n",
        "\n",
        "y_pred=model.predict(x_val/255.)\n",
        "y_pred_logical=(y_pred>0.5).astype(np.int)\n",
        "\n",
        "print(\"test acc: %s\"%accuracy_score(y_val,y_pred_logical))\n",
        "cm=confusion_matrix(y_val,y_pred_logical)\n",
        "sns.heatmap(cm,annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "OEcxnruwxETj",
        "outputId": "c88433ac-95b5-407a-ce64-cdcb3ddd0bb1"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test acc: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5b1ea459d0>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "qU_S3jLWCkhL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test\n",
        "\n",
        "import cv2, dlib\n",
        "import numpy as np\n",
        "from imutils import face_utils\n",
        "from keras.models import load_model\n",
        "\n",
        "IMG_SIZE = (34, 26)\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "model = load_model('2018_12_17_22_58_35.h5')\n",
        "model.summary()\n",
        "\n",
        "def crop_eye(img, eye_points):\n",
        "  x1, y1 = np.amin(eye_points, axis=0)\n",
        "  x2, y2 = np.amax(eye_points, axis=0)\n",
        "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "  w = (x2 - x1) * 1.2\n",
        "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
        "\n",
        "  margin_x, margin_y = w / 2, h / 2\n",
        "\n",
        "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
        "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
        "\n",
        "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
        "\n",
        "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
        "\n",
        "  return eye_img, eye_rect\n",
        "\n",
        "# main\n",
        "\n",
        "cap = cv2.VideoCapture('IMG_5990.MOV',cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, img_ori = cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "\n",
        "  img = img_ori.copy()\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = detector(gray)\n",
        "\n",
        "  for face in faces:\n",
        "    shapes = predictor(gray, face)\n",
        "    shapes = face_utils.shape_to_np(shapes)\n",
        "\n",
        "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
        "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
        "\n",
        "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
        "\n",
        "    cv2.imshow('l', eye_img_l)\n",
        "    cv2.imshow('r', eye_img_r)\n",
        "\n",
        "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
        "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
        "\n",
        "    pred_l = model.predict(eye_input_l)\n",
        "    pred_r = model.predict(eye_input_r)\n",
        "\n",
        "    # visualize\n",
        "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
        "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
        "\n",
        "    state_l = state_l % pred_l\n",
        "    state_r = state_r % pred_r\n",
        "\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
        "\n",
        "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "  \n",
        "  # img = cv2.imread('logo.png', cv2.IMREAD_UNCHANGED)\n",
        "  cv2_imshow(img)\n",
        "\n",
        "  # if cv2.waitKey(1) == ord('q'):\n",
        "    # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmOGx7Oa3rc_",
        "outputId": "7e624c9a-1d70-40d0-abea-05f17d6a9f99"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 26, 34, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 26, 34, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 17, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 13, 17, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 8, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 3, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1536)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               786944    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 880,129\n",
            "Trainable params: 880,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}